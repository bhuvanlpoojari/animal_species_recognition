{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import itertools\n",
    "import keras\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dropout, Flatten, Dense\n",
    "from keras import optimizers\n",
    "from keras.utils import to_categorical\n",
    "from keras.utils import img_to_array, load_img\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.callbacks import EarlyStopping\n",
    "import math\n",
    "import datetime\n",
    "import time\n",
    "\n",
    "import torch\n",
    "import torchvision.models as models\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.datasets import ImageFolder\n",
    "import torchvision.transforms as transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Default dimensions we found online\n",
    "img_width, img_height = 299, 299\n",
    "\n",
    "# Create a bottleneck file\n",
    "top_model_weights_path = 'pytorch_bottleneck_fc_model_inceptionv3.h5'\n",
    "\n",
    "# Loading up our datasets\n",
    "train_data_dir = 'data/train'\n",
    "validation_data_dir = 'data/validation'\n",
    "test_data_dir = 'data/test'\n",
    "\n",
    "# Number of epochs to train top model\n",
    "epochs = 100  # This has been changed after multiple model runs\n",
    "# Batch size used by flow_from_directory and predict_generator\n",
    "batch_size = 50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Feature extraction time for training data: 0:05:29.645817\n",
      "Feature extraction time for validation data: 0:00:35.083273\n",
      "Feature extraction time for test data: 0:00:38.137717\n"
     ]
    }
   ],
   "source": [
    "# Load pre-trained InceptionV3 model in PyTorch\n",
    "pytorch_model = models.inception_v3(pretrained=True)\n",
    "\n",
    "# Modify the last layer for feature extraction\n",
    "num_ftrs = pytorch_model.fc.in_features\n",
    "pytorch_model.fc = nn.Identity()\n",
    "\n",
    "# Define transforms for images\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((img_height, img_width)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "# Load datasets\n",
    "train_dataset = ImageFolder(train_data_dir, transform=transform)\n",
    "validation_dataset = ImageFolder(validation_data_dir, transform=transform)\n",
    "test_dataset = ImageFolder(test_data_dir, transform=transform)\n",
    "\n",
    "# Define dataloaders\n",
    "train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False)\n",
    "validation_loader = DataLoader(\n",
    "    validation_dataset, batch_size=batch_size, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "\n",
    "#1\n",
    "# # Feature extraction for training data\n",
    "# start = datetime.datetime.now()\n",
    "# train_features = []\n",
    "# train_labels = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in train_loader:\n",
    "#         features = pytorch_model(images)\n",
    "#         train_features.append(features)\n",
    "#         train_labels.append(labels)\n",
    "\n",
    "# train_features = torch.cat(train_features)\n",
    "# train_labels = torch.cat(train_labels)\n",
    "# np.save('train_features_inceptionv3.npy', train_features.numpy())\n",
    "# np.save('train_labels_inceptionv3.npy', train_labels.numpy())\n",
    "# end = datetime.datetime.now()\n",
    "# elapsed = end - start\n",
    "# print('Feature extraction time for training data:', elapsed)\n",
    "\n",
    "# # Feature extraction for validation data\n",
    "# start = datetime.datetime.now()\n",
    "# validation_features = []\n",
    "# validation_labels = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in validation_loader:\n",
    "#         features = pytorch_model(images)\n",
    "#         validation_features.append(features)\n",
    "#         validation_labels.append(labels)\n",
    "\n",
    "# validation_features = torch.cat(validation_features)\n",
    "# validation_labels = torch.cat(validation_labels)\n",
    "# np.save('validation_features_inceptionv3.npy', validation_features.numpy())\n",
    "# np.save('validation_labels_inceptionv3.npy', validation_labels.numpy())\n",
    "# end = datetime.datetime.now()\n",
    "# elapsed = end - start\n",
    "# print('Feature extraction time for validation data:', elapsed)\n",
    "\n",
    "# # Feature extraction for test data\n",
    "# start = datetime.datetime.now()\n",
    "# test_features = []\n",
    "# test_labels = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in test_loader:\n",
    "#         features = pytorch_model(images)\n",
    "#         test_features.append(features)\n",
    "#         test_labels.append(labels)\n",
    "\n",
    "# test_features = torch.cat(test_features)\n",
    "# test_labels = torch.cat(test_labels)\n",
    "# np.save('test_features_inceptionv3.npy', test_features.numpy())\n",
    "# np.save('test_labels_inceptionv3.npy', test_labels.numpy())\n",
    "# end = datetime.datetime.now()\n",
    "# elapsed = end - start\n",
    "# print('Feature extraction time for test data:', elapsed)\n",
    "\n",
    "#2\n",
    "# # Feature extraction for training data\n",
    "# start = datetime.datetime.now()\n",
    "# train_features = []\n",
    "# train_labels = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in train_loader:\n",
    "#         features = pytorch_model(images)\n",
    "#         train_features.append(features)\n",
    "#         train_labels.append(labels)\n",
    "\n",
    "# # Check if train_features contain InceptionOutputs, if so, convert them to tensors\n",
    "# if isinstance(train_features[0], torch.nn.modules.container.Sequential):\n",
    "#     train_features = [features[0] for features in train_features]\n",
    "\n",
    "# train_features = torch.cat(train_features)\n",
    "# train_labels = torch.cat(train_labels)\n",
    "# np.save('train_features_inceptionv3.npy', train_features.numpy())\n",
    "# np.save('train_labels_inceptionv3.npy', train_labels.numpy())\n",
    "# end = datetime.datetime.now()\n",
    "# elapsed = end - start\n",
    "# print('Feature extraction time for training data:', elapsed)\n",
    "\n",
    "# # Feature extraction for validation data\n",
    "# start = datetime.datetime.now()\n",
    "# validation_features = []\n",
    "# validation_labels = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in validation_loader:\n",
    "#         features = pytorch_model(images)\n",
    "#         validation_features.append(features)\n",
    "#         validation_labels.append(labels)\n",
    "\n",
    "# # Check if validation_features contain InceptionOutputs, if so, convert them to tensors\n",
    "# if isinstance(validation_features[0], torch.nn.modules.container.Sequential):\n",
    "#     validation_features = [features[0] for features in validation_features]\n",
    "\n",
    "# validation_features = torch.cat(validation_features)\n",
    "# validation_labels = torch.cat(validation_labels)\n",
    "# np.save('validation_features_inceptionv3.npy', validation_features.numpy())\n",
    "# np.save('validation_labels_inceptionv3.npy', validation_labels.numpy())\n",
    "# end = datetime.datetime.now()\n",
    "# elapsed = end - start\n",
    "# print('Feature extraction time for validation data:', elapsed)\n",
    "\n",
    "# # Feature extraction for test data\n",
    "# start = datetime.datetime.now()\n",
    "# test_features = []\n",
    "# test_labels = []\n",
    "\n",
    "# with torch.no_grad():\n",
    "#     for images, labels in test_loader:\n",
    "#         features = pytorch_model(images)\n",
    "#         test_features.append(features)\n",
    "#         test_labels.append(labels)\n",
    "\n",
    "# # Check if test_features contain InceptionOutputs, if so, convert them to tensors\n",
    "# if isinstance(test_features[0], torch.nn.modules.container.Sequential):\n",
    "#     test_features = [features[0] for features in test_features]\n",
    "\n",
    "# test_features = torch.cat(test_features)\n",
    "# test_labels = torch.cat(test_labels)\n",
    "# np.save('test_features_inceptionv3.npy', test_features.numpy())\n",
    "# np.save('test_labels_inceptionv3.npy', test_labels.numpy())\n",
    "# end = datetime.datetime.now()\n",
    "# elapsed = end - start\n",
    "# print('Feature extraction time for test data:', elapsed)\n",
    "\n",
    "#3\n",
    "# Feature extraction for training data\n",
    "start = datetime.datetime.now()\n",
    "train_features = []\n",
    "train_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in train_loader:\n",
    "        features = pytorch_model(images)\n",
    "\n",
    "        # Extract the desired features from InceptionOutputs\n",
    "        features = features.logits\n",
    "\n",
    "        train_features.append(features)\n",
    "        train_labels.append(labels)\n",
    "\n",
    "train_features = torch.cat(train_features)\n",
    "train_labels = torch.cat(train_labels)\n",
    "np.save('train_features_inceptionv3.npy', train_features.numpy())\n",
    "np.save('train_labels_inceptionv3.npy', train_labels.numpy())\n",
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print('Feature extraction time for training data:', elapsed)\n",
    "\n",
    "# Feature extraction for validation data\n",
    "start = datetime.datetime.now()\n",
    "validation_features = []\n",
    "validation_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in validation_loader:\n",
    "        features = pytorch_model(images)\n",
    "\n",
    "        # Extract the desired features from InceptionOutputs\n",
    "        features = features.logits\n",
    "\n",
    "        validation_features.append(features)\n",
    "        validation_labels.append(labels)\n",
    "\n",
    "validation_features = torch.cat(validation_features)\n",
    "validation_labels = torch.cat(validation_labels)\n",
    "np.save('validation_features_inceptionv3.npy', validation_features.numpy())\n",
    "np.save('validation_labels_inceptionv3.npy', validation_labels.numpy())\n",
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print('Feature extraction time for validation data:', elapsed)\n",
    "\n",
    "# Feature extraction for test data\n",
    "start = datetime.datetime.now()\n",
    "test_features = []\n",
    "test_labels = []\n",
    "\n",
    "with torch.no_grad():\n",
    "    for images, labels in test_loader:\n",
    "        features = pytorch_model(images)\n",
    "\n",
    "        # Extract the desired features from InceptionOutputs\n",
    "        features = features.logits\n",
    "\n",
    "        test_features.append(features)\n",
    "        test_labels.append(labels)\n",
    "\n",
    "test_features = torch.cat(test_features)\n",
    "test_labels = torch.cat(test_labels)\n",
    "np.save('test_features_inceptionv3.npy', test_features.numpy())\n",
    "np.save('test_labels_inceptionv3.npy', test_labels.numpy())\n",
    "end = datetime.datetime.now()\n",
    "elapsed = end - start\n",
    "print('Feature extraction time for test data:', elapsed)\n",
    "\n",
    "\n",
    "# Load features and labels\n",
    "train_data = np.load('train_features_inceptionv3.npy')\n",
    "train_labels = np.load('train_labels_inceptionv3.npy')\n",
    "validation_data = np.load('validation_features_inceptionv3.npy')\n",
    "validation_labels = np.load('validation_labels_inceptionv3.npy')\n",
    "test_data = np.load('test_features_inceptionv3.npy')\n",
    "test_labels = np.load('test_labels_inceptionv3.npy')\n",
    "\n",
    "# Convert target labels to one-hot encoded format\n",
    "train_labels = to_categorical(train_labels, num_classes=20)\n",
    "validation_labels = to_categorical(validation_labels, num_classes=20)\n",
    "test_labels = to_categorical(test_labels, num_classes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 3.2701 - acc: 0.0554 - val_loss: 3.0177 - val_acc: 0.0732\n",
      "Epoch 2/200\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 3.0924 - acc: 0.0646 - val_loss: 2.9581 - val_acc: 0.0915\n",
      "Epoch 3/200\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 2.9970 - acc: 0.0943 - val_loss: 2.9232 - val_acc: 0.1037\n",
      "Epoch 4/200\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 2.9187 - acc: 0.1088 - val_loss: 2.8883 - val_acc: 0.1159\n",
      "Epoch 5/200\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 2.8571 - acc: 0.1292 - val_loss: 2.8523 - val_acc: 0.1524\n",
      "Epoch 6/200\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 2.7942 - acc: 0.1549 - val_loss: 2.8132 - val_acc: 0.1646\n",
      "Epoch 7/200\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 2.6841 - acc: 0.1819 - val_loss: 2.7596 - val_acc: 0.1768\n",
      "Epoch 8/200\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 2.6045 - acc: 0.2109 - val_loss: 2.7119 - val_acc: 0.2256\n",
      "Epoch 9/200\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 2.5333 - acc: 0.2512 - val_loss: 2.6545 - val_acc: 0.2744\n",
      "Epoch 10/200\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 2.4351 - acc: 0.2808 - val_loss: 2.5847 - val_acc: 0.2927\n",
      "Epoch 11/200\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 2.3319 - acc: 0.3250 - val_loss: 2.5614 - val_acc: 0.3049\n",
      "Epoch 12/200\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 2.2600 - acc: 0.3533 - val_loss: 2.5006 - val_acc: 0.3232\n",
      "Epoch 13/200\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 2.1409 - acc: 0.4008 - val_loss: 2.4481 - val_acc: 0.3720\n",
      "Epoch 14/200\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 2.0731 - acc: 0.4305 - val_loss: 2.3730 - val_acc: 0.4085\n",
      "Epoch 15/200\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 1.9416 - acc: 0.4773 - val_loss: 2.3589 - val_acc: 0.3841\n",
      "Epoch 16/200\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.8628 - acc: 0.5003 - val_loss: 2.2771 - val_acc: 0.3963\n",
      "Epoch 17/200\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 1.7252 - acc: 0.5366 - val_loss: 2.2203 - val_acc: 0.4329\n",
      "Epoch 18/200\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 1.7241 - acc: 0.5465 - val_loss: 2.2215 - val_acc: 0.4390\n",
      "Epoch 19/200\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 1.6063 - acc: 0.5827 - val_loss: 2.1709 - val_acc: 0.4573\n",
      "Epoch 20/200\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 1.4893 - acc: 0.6170 - val_loss: 2.1382 - val_acc: 0.4878\n",
      "Epoch 21/200\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 1.4104 - acc: 0.6427 - val_loss: 2.1293 - val_acc: 0.4573\n",
      "Epoch 22/200\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 1.3540 - acc: 0.6546 - val_loss: 2.0803 - val_acc: 0.4268\n",
      "Epoch 23/200\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 1.2468 - acc: 0.7073 - val_loss: 2.0558 - val_acc: 0.5122\n",
      "Epoch 24/200\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.1588 - acc: 0.7304 - val_loss: 2.0577 - val_acc: 0.4573\n",
      "Epoch 25/200\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.1179 - acc: 0.7403 - val_loss: 2.0106 - val_acc: 0.4817\n",
      "Epoch 26/200\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 1.0240 - acc: 0.7811 - val_loss: 2.0049 - val_acc: 0.4695\n",
      "Epoch 27/200\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.9664 - acc: 0.7877 - val_loss: 1.9618 - val_acc: 0.4756\n",
      "Epoch 28/200\n",
      "31/31 [==============================] - 0s 16ms/step - loss: 0.8973 - acc: 0.7989 - val_loss: 1.9609 - val_acc: 0.4878\n",
      "Epoch 29/200\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.8482 - acc: 0.8154 - val_loss: 1.9640 - val_acc: 0.4939\n",
      "Epoch 30/200\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.7876 - acc: 0.8352 - val_loss: 1.9335 - val_acc: 0.4573\n",
      "Epoch 31/200\n",
      "31/31 [==============================] - 0s 13ms/step - loss: 0.7330 - acc: 0.8629 - val_loss: 1.9676 - val_acc: 0.4817\n",
      "Epoch 32/200\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.7007 - acc: 0.8596 - val_loss: 1.9330 - val_acc: 0.5122\n",
      "Epoch 33/200\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.6390 - acc: 0.8893 - val_loss: 1.9286 - val_acc: 0.5061\n",
      "Epoch 34/200\n",
      "31/31 [==============================] - 1s 20ms/step - loss: 0.6348 - acc: 0.8780 - val_loss: 1.9247 - val_acc: 0.4939\n",
      "Epoch 35/200\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.5950 - acc: 0.8906 - val_loss: 1.9237 - val_acc: 0.4817\n",
      "Epoch 36/200\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.5415 - acc: 0.9117 - val_loss: 1.9261 - val_acc: 0.4695\n",
      "Epoch 37/200\n",
      "31/31 [==============================] - 1s 16ms/step - loss: 0.4794 - acc: 0.9328 - val_loss: 1.9227 - val_acc: 0.4878\n",
      "Epoch 38/200\n",
      "31/31 [==============================] - 0s 14ms/step - loss: 0.4777 - acc: 0.9189 - val_loss: 1.9282 - val_acc: 0.4817\n",
      "Epoch 39/200\n",
      "31/31 [==============================] - 1s 19ms/step - loss: 0.4517 - acc: 0.9308 - val_loss: 1.9324 - val_acc: 0.4756\n",
      "Epoch 40/200\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.4037 - acc: 0.9354 - val_loss: 1.9138 - val_acc: 0.4695\n",
      "Epoch 41/200\n",
      "31/31 [==============================] - 0s 15ms/step - loss: 0.4092 - acc: 0.9295 - val_loss: 1.9409 - val_acc: 0.4695\n",
      "Epoch 42/200\n",
      "31/31 [==============================] - 1s 22ms/step - loss: 0.3691 - acc: 0.9433 - val_loss: 1.9314 - val_acc: 0.4939\n",
      "Epoch 43/200\n",
      "31/31 [==============================] - 1s 17ms/step - loss: 0.3483 - acc: 0.9407 - val_loss: 1.9459 - val_acc: 0.4695\n",
      "Epoch 43: early stopping\n",
      "4/4 [==============================] - 0s 4ms/step - loss: 1.9357 - acc: 0.4634\n",
      "[INFO] accuracy: 46.34%\n",
      "[INFO] Loss: 1.935681939125061\n"
     ]
    }
   ],
   "source": [
    "# Define the model architecture\n",
    "model = Sequential()\n",
    "model.add(Flatten(input_shape=train_data.shape[1:]))\n",
    "model.add(Dense(512, activation=keras.layers.LeakyReLU(\n",
    "    alpha=0.3)))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(128, activation=keras.layers.LeakyReLU(\n",
    "    alpha=0.3)))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(units=20, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=optimizers.Adam(lr=1e-4),\n",
    "              metrics=['acc'])\n",
    "\n",
    "early_stopping = EarlyStopping(\n",
    "    monitor='val_acc', patience=20, verbose=1, mode='max')\n",
    "\n",
    "# Train the model\n",
    "history = model.fit(train_data, train_labels,\n",
    "                    epochs=200,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(validation_data, validation_labels),\n",
    "                    callbacks=[early_stopping])\n",
    "\n",
    "# Save the trained model\n",
    "model.save_weights(top_model_weights_path)\n",
    "\n",
    "# Evaluate the model on the test data\n",
    "(eval_loss, eval_accuracy) = model.evaluate(\n",
    "    test_data, test_labels, batch_size=batch_size, verbose=1)\n",
    "\n",
    "# Print the evaluation results\n",
    "print(\"[INFO] accuracy: {:.2f}%\".format(eval_accuracy * 100))\n",
    "print(\"[INFO] Loss: {}\".format(eval_loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model summary\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Graphing our training and validation\n",
    "acc = history.history['acc']\n",
    "val_acc = history.history['val_acc']\n",
    "loss = history.history['loss']\n",
    "val_loss = history.history['val_loss']\n",
    "epochs = range(len(acc))\n",
    "plt.plot(epochs, acc, 'r', label='Training acc')\n",
    "plt.plot(epochs, val_acc, 'b', label='Validation acc')\n",
    "plt.title('Training and validation accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.figure()\n",
    "plt.plot(epochs, loss, 'r', label='Training loss')\n",
    "plt.plot(epochs, val_loss, 'b', label='Validation loss')\n",
    "plt.title('Training and validation loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.evaluate(test_data, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('test data', test_data)\n",
    "preds = np.round(model.predict(test_data), 0)\n",
    "# to fit them into classification metrics and confusion metrics, some additional modificaitions are required\n",
    "print('rounded test_labels', preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "animals = ['bear', 'cougar', 'coyote', 'cow', 'crocodiles', 'deer', 'elephant', 'giraffe', 'goat',\n",
    "           'gorilla', 'horse', 'kangaroo', 'leopard', 'lion', 'panda', 'penguin', 'sheep', 'skunk', 'tiger', 'zebra']\n",
    "classification_metrics = metrics.classification_report(\n",
    "    test_labels, preds, target_names=animals)\n",
    "print(classification_metrics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since our data is in dummy format we put the numpy array into a dataframe and call idxmax axis=1 to return the column\n",
    "# label of the maximum value thus creating a categorical variable\n",
    "# Basically, flipping a dummy variable back to it's categorical variable\n",
    "categorical_test_labels = pd.DataFrame(test_labels).idxmax(axis=1)\n",
    "categorical_preds = pd.DataFrame(preds).idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "confusion_matrix = confusion_matrix(categorical_test_labels, categorical_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues,\n",
    "                          figsize=(10, 8)):  # Adjust the figsize as per your preference\n",
    "    # Add Normalization Option\n",
    "    '''prints pretty confusion metric with normalization option '''\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    # Set figure size\n",
    "    plt.figure(figsize=figsize)\n",
    "\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "\n",
    "    # Rotate x-labels by 90 degrees\n",
    "    plt.xticks(tick_marks, classes, rotation=90)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        # Increase x-coordinate for more horizontal space\n",
    "        plt.text(j, i, format(cm[i, j], fmt), ha=\"center\", va=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_confusion_matrix(confusion_matrix, ['bear', 'cougar', 'coyote', 'cow', 'crocodiles', 'deer', 'elephant', 'giraffe',\n",
    "                      'goat', 'gorilla', 'horse', 'kangaroo', 'leopard', 'lion', 'panda', 'penguin', 'sheep', 'skunk', 'tiger', 'zebra'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Those numbers are all over the place. Now turning normalize= True\n",
    "plot_confusion_matrix(confusion_matrix,\n",
    "                      ['bear', 'cougar', 'coyote', 'cow', 'crocodiles', 'deer', 'elephant', 'giraffe', 'goat', 'gorilla',\n",
    "                          'horse', 'kangaroo', 'leopard', 'lion', 'panda', 'penguin', 'sheep', 'skunk', 'tiger', 'zebra'],\n",
    "                      normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import torch\n",
    "import torchvision.transforms as transforms\n",
    "from PIL import Image\n",
    "from keras.utils import img_to_array, load_img\n",
    "\n",
    "\n",
    "def read_image(path):\n",
    "    image = load_img(path, target_size=(299, 299))\n",
    "    image = img_to_array(image)\n",
    "    image = image / 255.0  # Normalize pixel values to [0, 1]\n",
    "    image = image.reshape((1,) + image.shape)  # Add batch dimension\n",
    "    return image\n",
    "\n",
    "\n",
    "def test_single_image(path):\n",
    "    animals = ['bear', 'cougar', 'coyote', 'cow', 'crocodiles', 'deer', 'elephant', 'giraffe', 'goat',\n",
    "               'gorilla', 'horse', 'kangaroo', 'leopard', 'lion', 'panda', 'penguin', 'sheep', 'skunk', 'tiger', 'zebra']\n",
    "\n",
    "    # Read and preprocess the image\n",
    "    image = read_image(path)\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    # Convert image to torch tensor\n",
    "    image = torch.tensor(image, dtype=torch.float32)\n",
    "    # Change dimension order to [batch_size, channels, height, width]\n",
    "    image = image.permute(0, 3, 1, 2)\n",
    "    image = image.to('cpu')  # Set to 'cuda' if you're using GPU\n",
    "\n",
    "    # Extract features using the pretrained InceptionV3 model\n",
    "    with torch.no_grad():\n",
    "        features = pytorch_model(image)\n",
    "\n",
    "    # Convert features to numpy array\n",
    "    features = features.detach().numpy()\n",
    "\n",
    "    # Make predictions using the trained model\n",
    "    preds = model.predict(features)\n",
    "\n",
    "    # Print individual class probabilities\n",
    "    for idx, animal, prob in zip(range(0, 20), animals, preds[0]):\n",
    "        print(\"ID: {}, Label: {} {}%\".format(\n",
    "            idx, animal, round(prob * 100, 2)))\n",
    "\n",
    "    print('Final Decision:')\n",
    "    time.sleep(0.5)\n",
    "\n",
    "    # Simulate decision-making process\n",
    "    for x in range(3):\n",
    "        print('.'*(x+1))\n",
    "        time.sleep(0.2)\n",
    "\n",
    "    # Determine the predicted class\n",
    "    class_prob = list(preds[0])\n",
    "    max_prob = max(class_prob)\n",
    "    pred_class = class_prob.index(max_prob)\n",
    "    print(\"ID: {}, Label: {}\".format(pred_class, animals[pred_class]))\n",
    "\n",
    "    return load_img(path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/test/kangaroo/5_78.jpg'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_single_image(path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
